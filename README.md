# kuavo_tasks
kuavo选拔任务
# 文件说明

## 运动控制

### `move_robot.py`
对应任务：“跑通项目的双足机器人的例子，如下图，并且编写一个脚本来向话题 `/cmd_vel` 发送数据控制机器人以指定的速度移动”。

启动该脚本后，可通过键盘按键向 `/cmd_vel` 话题发送消息控制 humanoid 仿真的运动方向：

- **s**: 前进  
- **w**: 后退  
- **a**: 向左  
- **d**: 向右  
- **q**: 左转  
- **e**: 右转  

代码使用了非阻塞输入，持续按下指定按键即可维持运动状态，无需回车。

---

### `move_vel.py`
对应任务：“自动切换步态的功能，即机器人在站立状态下向 `/cmd_vel` 发送不为 0 的速度可以自动向前走，同时发送为 0 的速度可以自动停止”。

启动脚本后，通过键盘输入速度数值可控制 humanoid 仿真的运动速度和步态：

- 输入任意非零速度：切换步态为 `walk`，设置 x 方向速度为输入值（`v > 0` 前进，`v < 0` 后退）。  
- 输入速度为 `0`：切换步态为 `stance`，速度归零。  

初始化状态下，步态为 `stance`。

---

## 视觉感知

### `yolo_test_train1.py`
模型训练脚本，采用的 YOLO 版本为 YOLOv8，数据集为 `handler`（训练集为 `image_1~91.jpg`，验证集为 `image_92~182.jpg`）。

---

### `test_pic.py`
通过图片检验 `yolo_test_train1.py` 训练所得模型的测试程序，测试对象为 `image_92.jpg`。

---

### `handler_test_vedio.py`
检验 `yolo_test_train1.py` 训练所得模型对于视频内容的识别效果的测试程序，视频来源是电脑摄像头。程序会基于 YOLO 和卡尔曼滤波预测框选出 `handler`，并用绿点标注预测中心；当检测目标被遮挡时，会基于卡尔曼滤波的预测，用红点继续标注预测的中心位置。
